{
  "instance_id": "Chinedum-iwueke__Bulletproof_bt-41",
  "repo": "Chinedum-iwueke/Bulletproof_bt",
  "base_commit": "b0c0d8765e8e5f7ae365abc74b104961a8e9c418",
  "version": "unknown",
  "created_at": "2026-02-13T21:14:23.198812+00:00",
  "problem_statement": "**Bug Report: Invalid Local Configuration Handling in Experiment Grid Runner**\n\n**Bug Report: Invalid Local Configuration Handling in Experiment Grid Runner**\n\n**Component Affected:** `scripts/run_experiment_grid.py`\n\n**Description of Issue:** The experiment grid runner does not adequately handle user-provided local configuration files when running experiments. If a user specifies a path to a local configuration file that does not exist, or if the file has an incorrect extension (not `.yaml` or `.yml`), the program will fail silently or may produce misleading errors, potentially leading to unintended experiment configurations. The expected behavior is to provide clear and informative validation errors when invalid local configuration files are specified, helping users quickly identify and correct the issue.\n\n**Expected Behavior:** The system should validate the existence and type of the provided local configuration file at the start of the experiment. If the provided file is missing or has an incorrect extension, a clear error message should be displayed to the user, preventing the execution of the experiment with an invalid configuration.",
  "patch": "diff --git a/scripts/run_experiment_grid.py b/scripts/run_experiment_grid.py\nindex 3d2bc39..d3b71af 100644\n--- a/scripts/run_experiment_grid.py\n+++ b/scripts/run_experiment_grid.py\n@@ -59,14 +59,19 @@ _SUMMARY_COLUMNS = [\n ]\n \n \n-def _load_yaml(path: Path) -> dict[str, Any]:\n-    with path.open(\"r\", encoding=\"utf-8\") as handle:\n+def _load_yaml_file(path: str) -> dict[str, Any]:\n+    yaml_path = Path(path)\n+    with yaml_path.open(\"r\", encoding=\"utf-8\") as handle:\n         data = yaml.safe_load(handle) or {}\n     if not isinstance(data, dict):\n-        raise ValueError(f\"Invalid YAML mapping at {path}\")\n+        raise ValueError(f\"Invalid YAML mapping at {yaml_path}\")\n     return data\n \n \n+def _load_yaml(path: Path) -> dict[str, Any]:\n+    return _load_yaml_file(str(path))\n+\n+\n def deep_merge(base: dict[str, Any], override: dict[str, Any]) -> dict[str, Any]:\n     merged = copy.deepcopy(base)\n     for key, value in override.items():\n@@ -284,10 +289,22 @@ def run_grid(\n     data_path: str,\n     out_path: Path,\n     *,\n+    local_config_path: str | None = None,\n     force: bool = False,\n     allow_failures: bool = False,\n ) -> int:\n     base_cfg = _load_yaml(config_path)\n+    local_cfg: dict[str, Any] = {}\n+    if local_config_path is not None:\n+        local_path = Path(local_config_path)\n+        if not local_path.exists():\n+            raise ValueError(f\"Invalid --local-config: file does not exist: {local_path}\")\n+        if local_path.suffix.lower() not in {\".yaml\", \".yml\"}:\n+            raise ValueError(\n+                f\"Invalid --local-config: expected a .yaml/.yml file, got: {local_path}\"\n+            )\n+        local_cfg = _load_yaml_file(str(local_path))\n+\n     exp_cfg = _load_yaml(experiment_path)\n     _validate_experiment(exp_cfg)\n \n@@ -312,6 +329,7 @@ def run_grid(\n                 \"grid_runs\": grid_runs,\n                 \"paths\": {\n                     \"config\": str(config_path),\n+                    \"local_config\": local_config_path,\n                     \"experiment\": str(experiment_path),\n                     \"data\": str(data_path),\n                 },\n@@ -330,28 +348,43 @@ def run_grid(\n     summary_rows: list[dict[str, Any]] = []\n \n     for index, params in enumerate(grid_runs, start=1):\n+        run_prefix = f\"run_{index:03d}\"\n         overrides = copy.deepcopy(fixed_overrides)\n         for dotpath, value in params.items():\n             set_by_dotpath(overrides, dotpath, value)\n \n-        run_cfg = deep_merge(base_cfg, overrides)\n-        run_cfg = resolve_config(run_cfg)\n-        _ensure_timeframe_config(run_cfg)\n+        merged_cfg = deep_merge(base_cfg, local_cfg)\n+        merged_cfg = deep_merge(merged_cfg, overrides)\n+\n+        run_suffix = \"run\"\n+        run_name_error: Exception | None = None\n+        try:\n+            run_suffix = _render_run_suffix(run_template, merged_cfg)\n+        except Exception as exc:  # pragma: no cover - rare invalid run_naming configs\n+            run_suffix = \"template_error\"\n+            run_name_error = exc\n \n-        run_suffix = _render_run_suffix(run_template, run_cfg)\n-        run_name = f\"run_{index:03d}__{run_suffix}\"\n+        run_name = f\"{run_prefix}__{run_suffix}\"\n         run_dir = runs_dir / run_name\n         run_dir.mkdir(parents=True, exist_ok=False)\n \n-        with (run_dir / \"config_used.yaml\").open(\"w\", encoding=\"utf-8\") as handle:\n-            yaml.safe_dump(run_cfg, handle, sort_keys=False)\n-        write_data_scope(\n-            run_dir,\n-            config=run_cfg,\n-            dataset_dir=data_path if Path(data_path).is_dir() else None,\n-        )\n-\n         try:\n+            if run_name_error is not None:\n+                raise ValueError(\n+                    f\"Invalid run naming template for run {run_prefix}: {run_name_error}\"\n+                )\n+\n+            run_cfg = resolve_config(merged_cfg)\n+            _ensure_timeframe_config(run_cfg)\n+\n+            with (run_dir / \"config_used.yaml\").open(\"w\", encoding=\"utf-8\") as handle:\n+                yaml.safe_dump(run_cfg, handle, sort_keys=False)\n+            write_data_scope(\n+                run_dir,\n+                config=run_cfg,\n+                dataset_dir=data_path if Path(data_path).is_dir() else None,\n+            )\n+\n             datafeed = load_feed(data_path, run_cfg)\n             engine = _build_engine(run_cfg, datafeed, run_dir)\n             engine.run()\n@@ -445,6 +478,7 @@ def main() -> None:\n     parser.add_argument(\"--experiment\", required=True)\n     parser.add_argument(\"--data\", required=True)\n     parser.add_argument(\"--out\", required=True)\n+    parser.add_argument(\"--local-config\")\n     parser.add_argument(\"--force\", action=\"store_true\")\n     parser.add_argument(\"--allow-failures\", action=\"store_true\")\n     args = parser.parse_args()\n@@ -454,6 +488,7 @@ def main() -> None:\n         experiment_path=Path(args.experiment),\n         data_path=args.data,\n         out_path=Path(args.out),\n+        local_config_path=args.local_config,\n         force=args.force,\n         allow_failures=args.allow_failures,\n     )\n",
  "test_patch": "diff --git a/tests/test_experiment_grid_local_config_overlay.py b/tests/test_experiment_grid_local_config_overlay.py\nnew file mode 100644\nindex 0000000..4656deb\n--- /dev/null\n+++ b/tests/test_experiment_grid_local_config_overlay.py\n@@ -0,0 +1,157 @@\n+from __future__ import annotations\n+\n+import importlib.util\n+from pathlib import Path\n+\n+import pandas as pd\n+import pytest\n+import yaml\n+\n+\n+def _load_run_grid_module():\n+    module_path = Path(__file__).resolve().parents[1] / \"scripts\" / \"run_experiment_grid.py\"\n+    spec = importlib.util.spec_from_file_location(\"run_experiment_grid\", module_path)\n+    assert spec and spec.loader\n+    module = importlib.util.module_from_spec(spec)\n+    spec.loader.exec_module(module)\n+    return module\n+\n+\n+def _write_dataset(dataset_dir: Path) -> Path:\n+    dataset_dir.mkdir(parents=True, exist_ok=True)\n+    ts_index = pd.date_range(\"2024-01-01\", periods=5, freq=\"min\", tz=\"UTC\")\n+    rows: list[dict[str, object]] = []\n+    for i, ts in enumerate(ts_index):\n+        base = 100 + i\n+        rows.append(\n+            {\n+                \"ts\": ts,\n+                \"symbol\": \"BTCUSDT\",\n+                \"open\": float(base),\n+                \"high\": float(base + 1),\n+                \"low\": float(base - 1),\n+                \"close\": float(base + 0.5),\n+                \"volume\": float(1000 + i),\n+            }\n+        )\n+    bars = pd.DataFrame(rows)\n+    bars.to_parquet(dataset_dir / \"bars.parquet\", index=False)\n+    with (dataset_dir / \"manifest.yaml\").open(\"w\", encoding=\"utf-8\") as handle:\n+        yaml.safe_dump({\"version\": 1, \"format\": \"parquet\", \"files\": [\"bars.parquet\"]}, handle, sort_keys=False)\n+    return dataset_dir / \"bars.parquet\"\n+\n+\n+def _write_base_config(path: Path) -> None:\n+    cfg = {\n+        \"execution_tier\": 2,\n+        \"initial_cash\": 10000.0,\n+        \"max_leverage\": 2.0,\n+        \"signal_delay_bars\": 0,\n+        \"risk\": {\"max_positions\": 5, \"risk_per_trade_pct\": 0.001},\n+        \"strategy\": {\"name\": \"coinflip\", \"p_trade\": 0.0, \"cooldown_bars\": 0},\n+    }\n+    path.write_text(yaml.safe_dump(cfg, sort_keys=False), encoding=\"utf-8\")\n+\n+\n+def _write_experiment(path: Path, *, fixed: dict | None = None, grid: dict | None = None) -> None:\n+    exp = {\n+        \"version\": 1,\n+        \"fixed\": fixed or {\"strategy\": {\"name\": \"coinflip\"}},\n+        \"grid\": grid or {\"strategy.p_trade\": [1.0], \"strategy.cooldown_bars\": [0]},\n+    }\n+    path.write_text(yaml.safe_dump(exp, sort_keys=False), encoding=\"utf-8\")\n+\n+\n+def _load_single_run_cfg(out_dir: Path) -> dict:\n+    run_dirs = sorted((out_dir / \"runs\").iterdir())\n+    assert len(run_dirs) == 1\n+    cfg_path = run_dirs[0] / \"config_used.yaml\"\n+    assert cfg_path.exists()\n+    return yaml.safe_load(cfg_path.read_text(encoding=\"utf-8\"))\n+\n+\n+def test_local_overlay_applied(tmp_path: Path) -> None:\n+    module = _load_run_grid_module()\n+    base_path = tmp_path / \"engine.yaml\"\n+    local_path = tmp_path / \"engine.local.yaml\"\n+    exp_path = tmp_path / \"experiment.yaml\"\n+    out_path = tmp_path / \"out\"\n+\n+    _write_base_config(base_path)\n+    local_path.write_text(\n+        yaml.safe_dump({\"risk\": {\"max_positions\": 1}, \"data\": {\"symbols_subset\": [\"BTCUSDT\"]}}, sort_keys=False),\n+        encoding=\"utf-8\",\n+    )\n+    _write_experiment(exp_path)\n+    data_path = _write_dataset(tmp_path / \"dataset\")\n+\n+    exit_code = module.run_grid(base_path, exp_path, str(data_path), out_path, local_config_path=str(local_path))\n+    assert exit_code == 0\n+\n+    run_cfg = _load_single_run_cfg(out_path)\n+    assert run_cfg[\"risk\"][\"max_positions\"] == 1\n+    assert run_cfg[\"data\"][\"symbols_subset\"] == [\"BTCUSDT\"]\n+\n+\n+def test_precedence_fixed_beats_local(tmp_path: Path) -> None:\n+    module = _load_run_grid_module()\n+    base_path = tmp_path / \"engine.yaml\"\n+    local_path = tmp_path / \"engine.local.yaml\"\n+    exp_path = tmp_path / \"experiment.yaml\"\n+    out_path = tmp_path / \"out\"\n+\n+    _write_base_config(base_path)\n+    local_path.write_text(yaml.safe_dump({\"risk\": {\"max_positions\": 1}}, sort_keys=False), encoding=\"utf-8\")\n+    _write_experiment(exp_path, fixed={\"strategy\": {\"name\": \"coinflip\"}, \"risk\": {\"max_positions\": 3}})\n+    data_path = _write_dataset(tmp_path / \"dataset\")\n+\n+    exit_code = module.run_grid(base_path, exp_path, str(data_path), out_path, local_config_path=str(local_path))\n+    assert exit_code == 0\n+\n+    run_cfg = _load_single_run_cfg(out_path)\n+    assert run_cfg[\"risk\"][\"max_positions\"] == 3\n+\n+\n+def test_precedence_grid_beats_local_and_fixed(tmp_path: Path) -> None:\n+    module = _load_run_grid_module()\n+    base_path = tmp_path / \"engine.yaml\"\n+    local_path = tmp_path / \"engine.local.yaml\"\n+    exp_path = tmp_path / \"experiment.yaml\"\n+    out_path = tmp_path / \"out\"\n+\n+    _write_base_config(base_path)\n+    local_path.write_text(yaml.safe_dump({\"strategy\": {\"p_trade\": 0.1}}, sort_keys=False), encoding=\"utf-8\")\n+    _write_experiment(\n+        exp_path,\n+        fixed={\"strategy\": {\"name\": \"coinflip\", \"p_trade\": 0.2}},\n+        grid={\"strategy.p_trade\": [0.9], \"strategy.cooldown_bars\": [0]},\n+    )\n+    data_path = _write_dataset(tmp_path / \"dataset\")\n+\n+    exit_code = module.run_grid(base_path, exp_path, str(data_path), out_path, local_config_path=str(local_path))\n+    assert exit_code == 0\n+\n+    run_cfg = _load_single_run_cfg(out_path)\n+    assert run_cfg[\"strategy\"][\"p_trade\"] == 0.9\n+\n+\n+def test_missing_local_config_path_raises_clear_error(tmp_path: Path) -> None:\n+    module = _load_run_grid_module()\n+    base_path = tmp_path / \"engine.yaml\"\n+    exp_path = tmp_path / \"experiment.yaml\"\n+    out_path = tmp_path / \"out\"\n+\n+    _write_base_config(base_path)\n+    _write_experiment(exp_path)\n+    data_path = _write_dataset(tmp_path / \"dataset\")\n+\n+    missing_path = \"/nope/missing.yaml\"\n+    with pytest.raises(ValueError, match=r\"local-config\") as exc_info:\n+        module.run_grid(\n+            base_path,\n+            exp_path,\n+            str(data_path),\n+            out_path,\n+            local_config_path=missing_path,\n+        )\n+    assert missing_path in str(exc_info.value)\n",
  "hints_text": "",
  "environment_setup_commit": "b0c0d8765e8e5f7ae365abc74b104961a8e9c418",
  "install_config": {
    "python": "3.11",
    "packages": "pyproject.toml",
    "install": "pip install -e .[dev]",
    "test_cmd": "pytest --no-header -rA --tb=line --color=no -p no:cacheprovider -W ignore::DeprecationWarning",
    "pip_packages": [
      "setuptools>=68",
      "wheel"
    ],
    "pre_install": [],
    "reqs_path": [],
    "env_yml_path": []
  },
  "meta": {
    "commit_name": "head_commit",
    "num_modified_files": 1,
    "has_test_patch": true,
    "is_lite": true,
    "llm_score": {
      "difficulty_score": null,
      "issue_text_score": null,
      "test_score": null
    }
  },
  "license_name": null,
  "FAIL_TO_PASS": [],
  "PASS_TO_PASS": [],
  "requirements": "",
  "environment": ""
}