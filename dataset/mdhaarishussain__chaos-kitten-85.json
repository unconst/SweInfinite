{
  "instance_id": "mdhaarishussain__chaos-kitten-85",
  "repo": "mdhaarishussain/chaos-kitten",
  "base_commit": "22425c5a0114f5557560008fc04c05aa15d77722",
  "version": "unknown",
  "created_at": "2026-02-13T17:26:33.358291+00:00",
  "problem_statement": "[Brain] Add GraphQL Schema Parsing Support\n\n## Task\nAdd GraphQL schema parsing support to the OpenAPI parser module, enabling Chaos Kitten to test GraphQL APIs in addition to REST APIs.\n\n## Context\nThe PRD Phase 2 roadmap lists GraphQL support. Many modern APIs use GraphQL, and AI-generated GraphQL backends are especially vulnerable to:\n- **Introspection attacks** (query `__schema` to discover all types/fields)\n- **Deep query nesting** (DoS via deeply nested queries)\n- **Batch query attacks** (send multiple operations in one request)\n- **Field-level injection** (SQL/NoSQL injection via query arguments)\n\n## Requirements\n\n### New Module: `chaos_kitten/brain/graphql_parser.py`\nCreate a `GraphQLParser` class:\n\n```python\nclass GraphQLParser:\n    def __init__(self, endpoint_url: str = None, schema_path: str = None):\n        \"\"\"Initialize with either a live endpoint or local schema file.\"\"\"\n    \n    def introspect(self) -> dict:\n        \"\"\"Send introspection query to live endpoint, return schema.\"\"\"\n    \n    def parse_schema(self) -> dict:\n        \"\"\"Parse a local .graphql or .json schema file.\"\"\"\n    \n    def get_queries(self) -> list[dict]:\n        \"\"\"Extract all Query type fields with arguments.\"\"\"\n    \n    def get_mutations(self) -> list[dict]:\n        \"\"\"Extract all Mutation type fields with arguments.\"\"\"\n    \n    def get_types(self) -> list[dict]:\n        \"\"\"Extract all custom types with their fields.\"\"\"\n    \n    def to_endpoints(self) -> list[dict]:\n        \"\"\"Convert GraphQL operations to endpoint-like format for the AttackPlanner.\"\"\"\n```\n\n### Introspection Query\n- Implement the standard GraphQL introspection query (`__schema { types { ... } }`)\n- Parse the response into structured types, queries, and mutations\n- Extract argument names, types, and whether they're required\n\n### Schema \u2192 Endpoint Conversion\n- Convert GraphQL operations to a format compatible with AttackPlanner:\n  ```python\n  {\n      \"path\": \"/graphql\",\n      \"method\": \"POST\",\n      \"operation\": \"mutation createUser\",\n      \"fields\": [\n          {\"name\": \"username\", \"type\": \"String!\", \"required\": True},\n          {\"name\": \"email\", \"type\": \"String!\", \"required\": True}\n      ]\n  }\n  ```\n\n### Config Support\n- Update `chaos-kitten.yaml` schema to support GraphQL targets:\n  ```yaml\n  target:\n    type: \"graphql\"  # or \"rest\" (default)\n    graphql_endpoint: \"http://localhost:4000/graphql\"\n    graphql_schema: \"./schema.graphql\"  # optional local schema\n  ```\n\n## Acceptance Criteria\n- [ ] `chaos_kitten/brain/graphql_parser.py` exists with `GraphQLParser` class\n- [ ] Introspection query works against a live GraphQL endpoint\n- [ ] Local `.graphql` schema file parsing works\n- [ ] Queries and Mutations extracted with argument types\n- [ ] Converted to endpoint-like format for AttackPlanner compatibility\n- [ ] Config schema updated to support `target.type: \"graphql\"`\n- [ ] Unit tests with mocked introspection responses\n- [ ] Updated `chaos_kitten/brain/__init__.py` to export new class\n\n## Apertre 3.0\n**Difficulty:** Hard | **Points:** 10\n\nTo get assigned, comment below with:\n```\nI'd like to work on this!\nDiscord: [your_discord_username]\nApproach: [brief description of how you'll tackle this]\n```\n\n**Verification Checklist:**\n- [ ] Forked the repository\n- [ ] Read CONTRIBUTING.md\n- [ ] Discord username matches Apertre 3.0 registration",
  "patch": "diff --git a/chaos_kitten/brain/__init__.py b/chaos_kitten/brain/__init__.py\nindex 70f9dc7..7287639 100644\n--- a/chaos_kitten/brain/__init__.py\n+++ b/chaos_kitten/brain/__init__.py\n@@ -2,6 +2,7 @@\n \n from chaos_kitten.brain.orchestrator import Orchestrator\n from chaos_kitten.brain.openapi_parser import OpenAPIParser\n+from chaos_kitten.brain.graphql_parser import GraphQLParser\n from chaos_kitten.brain.attack_planner import AttackPlanner\n \n-__all__ = [\"Orchestrator\", \"OpenAPIParser\", \"AttackPlanner\"]\n+__all__ = [\"Orchestrator\", \"OpenAPIParser\", \"GraphQLParser\", \"AttackPlanner\"]\ndiff --git a/chaos_kitten/brain/graphql_parser.py b/chaos_kitten/brain/graphql_parser.py\nnew file mode 100644\nindex 0000000..b35b316\n--- /dev/null\n+++ b/chaos_kitten/brain/graphql_parser.py\n@@ -0,0 +1,328 @@\n+\"\"\"GraphQL Schema Parser.\n+\n+This module provides the `GraphQLParser` class, which parses GraphQL schemas\n+from live endpoints (introspection) or local files (.graphql/.json) and\n+converts them into a format compatible with the Chaos Kitten Attack Planner.\n+\"\"\"\n+\n+from __future__ import annotations\n+import json\n+import logging\n+from pathlib import Path\n+from typing import Any, Dict, List\n+from urllib.parse import urlparse\n+import httpx\n+\n+# Try to import graphql for SDL parsing\n+try:\n+    from graphql import build_schema, introspection_from_schema\n+    HAS_GRAPHQL_CORE = True\n+except ImportError:\n+    HAS_GRAPHQL_CORE = False\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class GraphQLParser:\n+    \"\"\"Parses GraphQL schemas from endpoints or local files.\"\"\"\n+\n+    # Standard Introspection Query to retrieve the full schema\n+    INTROSPECTION_QUERY = \"\"\"\n+    query IntrospectionQuery {\n+      __schema {\n+        queryType { name }\n+        mutationType { name }\n+        subscriptionType { name }\n+        types {\n+          ...FullType\n+        }\n+        directives {\n+          name\n+          description\n+          locations\n+          args {\n+            ...InputValue\n+          }\n+        }\n+      }\n+    }\n+    fragment FullType on __Type {\n+      kind\n+      name\n+      description\n+      fields(includeDeprecated: true) {\n+        name\n+        description\n+        args {\n+          ...InputValue\n+        }\n+        type {\n+          ...TypeRef\n+        }\n+        isDeprecated\n+        deprecationReason\n+      }\n+      inputFields {\n+        ...InputValue\n+      }\n+      interfaces {\n+        ...TypeRef\n+      }\n+      enumValues(includeDeprecated: true) {\n+        name\n+        description\n+        isDeprecated\n+        deprecationReason\n+      }\n+      possibleTypes {\n+        ...TypeRef\n+      }\n+    }\n+    fragment InputValue on __InputValue {\n+      name\n+      description\n+      type { ...TypeRef }\n+      defaultValue\n+    }\n+    fragment TypeRef on __Type {\n+      kind\n+      name\n+      ofType {\n+        kind\n+        name\n+        ofType {\n+          kind\n+          name\n+          ofType {\n+            kind\n+            name\n+            ofType {\n+              kind\n+              name\n+              ofType {\n+                kind\n+                name\n+                ofType {\n+                  kind\n+                  name\n+                  ofType {\n+                    kind\n+                    name\n+                  }\n+                }\n+              }\n+            }\n+          }\n+        }\n+      }\n+    }\n+    \"\"\"\n+\n+    def __init__(self, endpoint_url: str | None = None, schema_path: str | Path | None = None) -> None:\n+        \"\"\"Initialize with either a live endpoint or local schema file.\n+\n+        Args:\n+            endpoint_url: URL of the GraphQL API endpoint.\n+            schema_path: Path to a local .graphql or .json schema file.\n+        \"\"\"\n+        self.endpoint_url = endpoint_url\n+        self.schema_path = Path(schema_path) if schema_path else None\n+        self.schema: Dict[str, Any] = {}\n+\n+        if not self.endpoint_url and not self.schema_path:\n+            # We allow init without args technically if we plan to set late, \n+            # but usually for this tool we want one. \n+            # Requirements don't strictly forbid it, but let's be safe.\n+            pass\n+\n+    def introspect(self) -> dict[str, Any]:\n+        \"\"\"Send introspection query to live endpoint, return schema.\n+        \n+        Returns:\n+            The introspection result (dict with __schema key).\n+        \"\"\"\n+        if not self.endpoint_url:\n+            raise ValueError(\"No endpoint_url provided for introspection\")\n+\n+        try:\n+            logger.info(f\"Introspecting GraphQL endpoint: {self.endpoint_url}\")\n+            response = httpx.post(\n+                self.endpoint_url,\n+                json={\"query\": self.INTROSPECTION_QUERY},\n+                timeout=30.0\n+            )\n+            response.raise_for_status()\n+            data = response.json()\n+\n+            if \"errors\" in data and data[\"errors\"]:\n+                raise ValueError(f\"GraphQL Introspection returned errors: {data['errors']}\")\n+\n+            if \"data\" not in data or \"__schema\" not in data[\"data\"]:\n+                raise ValueError(\"Invalid introspection response: missing __schema\")\n+\n+            self.schema = data[\"data\"]\n+            return self.schema\n+\n+        except httpx.RequestError as e:\n+            logger.error(f\"Network error interacting with GraphQL endpoint: {e}\")\n+            raise\n+        except Exception as e:\n+            logger.error(f\"Failed to introspect GraphQL endpoint: {e}\")\n+            raise\n+\n+    def parse_schema(self) -> dict[str, Any]:\n+        \"\"\"Parse a local .graphql or .json schema file.\n+        \n+        Returns:\n+            The parsed schema dictionary.\n+        \"\"\"\n+        if not self.schema_path or not self.schema_path.exists():\n+            raise FileNotFoundError(f\"Schema file not found: {self.schema_path}\")\n+\n+        try:\n+            content = self.schema_path.read_text(encoding=\"utf-8\")\n+\n+            if self.schema_path.suffix == \".json\":\n+                data = json.loads(content)\n+                # Check if it's wrapped in data or just schema\n+                if \"data\" in data and \"__schema\" in data[\"data\"]:\n+                    self.schema = data[\"data\"]\n+                elif \"__schema\" in data:\n+                    self.schema = data\n+                else:\n+                    raise ValueError(\"JSON file does not appear to be a standard introspection result (missing __schema)\")\n+\n+            elif self.schema_path.suffix in [\".graphql\", \".gql\"]:\n+                if not HAS_GRAPHQL_CORE:\n+                    raise ImportError(\n+                        \"graphql-core library is required to parse .graphql files. \"\n+                        \"Install it with 'pip install graphql-core'\"\n+                    )\n+\n+                # Parse SDL to schema object, then convert to introspection dict for consistency\n+                graphql_schema = build_schema(content)\n+                introspection_result = introspection_from_schema(graphql_schema)\n+                # introspection_from_schema returns the dict matching __schema structure directly?\n+                # Actually it typically returns {'__schema': ...} or just the schema obj.\n+                # Let's verify standard behavior. usually `introspection_from_schema` returns the schema part.\n+                # But to be safe and consistent with our self.schema expectation (containing __schema key at root?)\n+                # Wait, self.schema = data[\"data\"] where data[\"data\"] has \"__schema\".\n+                # So self.schema should contain \"__schema\".\n+                \n+                # introspection_from_schema returns a dict with \"__schema\" key?\n+                # No, it returns the schema dict. let's check.\n+                # Check `graphql.utilities.introspection_from_schema` doc or assume standard.\n+                # Assuming it returns the Dict that usually goes under \"data\".\n+                \n+                self.schema = introspection_result\n+\n+            else:\n+                raise ValueError(f\"Unsupported file extension: {self.schema_path.suffix}\")\n+\n+            return self.schema\n+\n+        except Exception as e:\n+            logger.error(f\"Failed to parse schema file: {e}\")\n+            raise\n+\n+    def get_queries(self) -> list[dict[str, Any]]:\n+        \"\"\"Extract all Query type fields with arguments.\"\"\"\n+        if not self.schema:\n+            return []\n+\n+        query_type_name = self.schema[\"__schema\"].get(\"queryType\", {}).get(\"name\", \"Query\")\n+        return self._get_fields_for_type(query_type_name)\n+\n+    def get_mutations(self) -> list[dict[str, Any]]:\n+        \"\"\"Extract all Mutation type fields with arguments.\"\"\"\n+        if not self.schema:\n+            return []\n+\n+        mutation_type_obj = self.schema[\"__schema\"].get(\"mutationType\")\n+        if not mutation_type_obj:\n+            return []\n+\n+        mutation_type_name = mutation_type_obj.get(\"name\", \"Mutation\")\n+        return self._get_fields_for_type(mutation_type_name)\n+\n+    def get_types(self) -> list[dict[str, Any]]:\n+        \"\"\"Extract all custom types with their fields.\"\"\"\n+        if not self.schema:\n+            return []\n+\n+        types = []\n+        for type_def in self.schema[\"__schema\"][\"types\"]:\n+            if type_def[\"kind\"] == \"OBJECT\" and not type_def[\"name\"].startswith(\"__\"):\n+                types.append(type_def)\n+        return types\n+\n+    def _get_fields_for_type(self, type_name: str) -> list[dict[str, Any]]:\n+        fields = []\n+        types = self.schema[\"__schema\"][\"types\"]\n+\n+        target_type = next((t for t in types if t[\"name\"] == type_name), None)\n+        if not target_type or \"fields\" not in target_type or not target_type[\"fields\"]:\n+            return []\n+\n+        for field in target_type[\"fields\"]:\n+            fields.append({\n+                \"name\": field[\"name\"],\n+                \"description\": field.get(\"description\"),\n+                \"args\": [\n+                    {\n+                        \"name\": arg[\"name\"],\n+                        \"type\": self._resolve_type_name(arg[\"type\"]),\n+                        \"required\": arg[\"type\"][\"kind\"] == \"NON_NULL\"\n+                    }\n+                    for arg in field.get(\"args\", [])\n+                ],\n+                \"type\": self._resolve_type_name(field[\"type\"])\n+            })\n+        return fields\n+\n+    def _resolve_type_name(self, type_ref: dict[str, Any] | None) -> str:\n+        \"\"\"Helper to reconstruct type signature (e.g. String!, [User]).\"\"\"\n+        if not type_ref:\n+            return \"Unknown\"\n+\n+        kind = type_ref.get(\"kind\")\n+        name = type_ref.get(\"name\")\n+        of_type = type_ref.get(\"ofType\")\n+\n+        if kind == \"NON_NULL\":\n+            return f\"{self._resolve_type_name(of_type)}!\"\n+        elif kind == \"LIST\":\n+            return f\"[{self._resolve_type_name(of_type)}]\"\n+        else:\n+            return name if name else \"Unknown\"\n+\n+    def to_endpoints(self) -> list[dict[str, Any]]:\n+        \"\"\"Convert GraphQL operations to endpoint-like format for the AttackPlanner.\"\"\"\n+        endpoints = []\n+\n+        path = \"/graphql\"\n+        if self.endpoint_url:\n+            parsed = urlparse(self.endpoint_url)\n+            path = parsed.path\n+\n+        # Add Mutation operations\n+        mutations = self.get_mutations()\n+        for op in mutations:\n+            endpoints.append({\n+                \"path\": path,\n+                \"method\": \"POST\",\n+                \"operation\": f\"mutation {op['name']}\",\n+                \"fields\": op[\"args\"]  # Already has name, type, required\n+            })\n+\n+        # Add Query operations\n+        queries = self.get_queries()\n+        for op in queries:\n+            endpoints.append({\n+                \"path\": path,\n+                \"method\": \"POST\",  # Queries are typically POSTed\n+                \"operation\": f\"query {op['name']}\",\n+                \"fields\": op[\"args\"]\n+            })\n+\n+        return endpoints\ndiff --git a/chaos_kitten/utils/config.py b/chaos_kitten/utils/config.py\nindex dfd2199..a81edcf 100644\n--- a/chaos_kitten/utils/config.py\n+++ b/chaos_kitten/utils/config.py\n@@ -71,8 +71,16 @@ class Config:\n             if field not in self._config:\n                 raise ValueError(f\"Missing required configuration field: {field}\")\n         \n-        if \"base_url\" not in self._config.get(\"target\", {}):\n-            raise ValueError(\"Missing required field: target.base_url\")\n+        target = self._config.get(\"target\", {})\n+        target_type = target.get(\"type\", \"rest\")\n+        \n+        if target_type == \"graphql\":\n+            if \"graphql_endpoint\" not in target and \"graphql_schema\" not in target:\n+                raise ValueError(\"GraphQL target requires either 'graphql_endpoint' or 'graphql_schema'\")\n+        else:\n+            # Default to REST behavior\n+            if \"base_url\" not in target:\n+                raise ValueError(\"Missing required field: target.base_url\")\n     \n     @property\n     def target(self) -> dict[str, Any]:\ndiff --git a/pyproject.toml b/pyproject.toml\nindex 1ab1f76..17bb755 100644\n--- a/pyproject.toml\n+++ b/pyproject.toml\n@@ -49,6 +49,7 @@ dependencies = [\n     \"prance[osv]>=23.0.0\",\n     \"jsonschema>=4.0\",\n     \"requests>=2.32.4\",\n+    \"graphql-core>=3.2.0\",\n ]\n \n [project.optional-dependencies]\n",
  "test_patch": "diff --git a/tests/test_graphql_parser.py b/tests/test_graphql_parser.py\nnew file mode 100644\nindex 0000000..b186f34\n--- /dev/null\n+++ b/tests/test_graphql_parser.py\n@@ -0,0 +1,138 @@\n+\"\"\"Tests for the GraphQL Parser.\"\"\"\n+\n+import json\n+import pytest\n+from unittest.mock import MagicMock, patch\n+import httpx\n+from chaos_kitten.brain.graphql_parser import GraphQLParser\n+\n+class TestGraphQLParser:\n+    \"\"\"Tests for GraphQLParser.\"\"\"\n+\n+    @pytest.fixture\n+    def mock_introspection_response(self):\n+        return {\n+            \"data\": {\n+                \"__schema\": {\n+                    \"queryType\": {\"name\": \"RootQuery\"},\n+                    \"mutationType\": {\"name\": \"RootMutation\"},\n+                    \"types\": [\n+                        {\n+                            \"kind\": \"OBJECT\",\n+                            \"name\": \"RootQuery\",\n+                            \"fields\": [\n+                                {\n+                                    \"name\": \"getUser\",\n+                                    \"description\": \"Get user by ID\",\n+                                    \"args\": [\n+                                        {\n+                                            \"name\": \"id\",\n+                                            \"type\": {\"kind\": \"NON_NULL\", \"name\": None, \"ofType\": {\"kind\": \"SCALAR\", \"name\": \"ID\"}}\n+                                        }\n+                                    ],\n+                                    \"type\": {\"kind\": \"OBJECT\", \"name\": \"User\"}\n+                                }\n+                            ]\n+                        },\n+                        {\n+                            \"kind\": \"OBJECT\",\n+                            \"name\": \"RootMutation\",\n+                            \"fields\": [\n+                                {\n+                                    \"name\": \"createUser\",\n+                                    \"args\": [\n+                                        {\n+                                            \"name\": \"username\",\n+                                            \"type\": {\"kind\": \"NON_NULL\", \"name\": None, \"ofType\": {\"kind\": \"SCALAR\", \"name\": \"String\"}}\n+                                        }\n+                                    ],\n+                                    \"type\": {\"kind\": \"OBJECT\", \"name\": \"User\"}\n+                                }\n+                            ]\n+                        },\n+                         {\n+                            \"kind\": \"OBJECT\",\n+                            \"name\": \"User\",\n+                            \"fields\": [\n+                                {\"name\": \"id\", \"type\": {\"kind\": \"SCALAR\", \"name\": \"ID\"}},\n+                                {\"name\": \"username\", \"type\": {\"kind\": \"SCALAR\", \"name\": \"String\"}}\n+                            ]\n+                        }\n+                    ]\n+                }\n+            }\n+        }\n+\n+    @patch(\"httpx.post\")\n+    def test_introspect_success(self, mock_post, mock_introspection_response):\n+        \"\"\"Test successful introspection from an endpoint.\"\"\"\n+        mock_response = MagicMock()\n+        mock_response.json.return_value = mock_introspection_response\n+        mock_response.raise_for_status.return_value = None\n+        mock_post.return_value = mock_response\n+\n+        parser = GraphQLParser(endpoint_url=\"http://example.com/graphql\")\n+        schema = parser.introspect()\n+\n+        assert schema == mock_introspection_response[\"data\"]\n+        mock_post.assert_called_once()\n+    \n+    @patch(\"httpx.post\")\n+    def test_introspect_failure(self, mock_post):\n+        \"\"\"Test introspection failure handling.\"\"\"\n+        mock_post.side_effect = httpx.RequestError(\"Network error\")\n+        parser = GraphQLParser(endpoint_url=\"http://example.com/graphql\")\n+        \n+        with pytest.raises(httpx.RequestError):\n+            parser.introspect()\n+\n+    def test_parse_schema_json(self, mock_introspection_response):\n+        \"\"\"Test parsing a local JSON schema file.\"\"\"\n+        import json\n+        json_content = json.dumps(mock_introspection_response[\"data\"])\n+        \n+        with patch(\"pathlib.Path.read_text\", return_value=json_content), \\\n+             patch(\"pathlib.Path.exists\", return_value=True):\n+            \n+            parser = GraphQLParser(schema_path=\"schema.json\")\n+            schema = parser.parse_schema()\n+            assert schema[\"__schema\"][\"queryType\"][\"name\"] == \"RootQuery\"\n+\n+    def test_to_endpoints(self, mock_introspection_response):\n+        \"\"\"Test conversion of schema to endpoint list.\"\"\"\n+        parser = GraphQLParser(endpoint_url=\"http://example.com/api/graphql\")\n+        # Manually set schema to avoid introspection call\n+        parser.schema = mock_introspection_response[\"data\"]\n+        \n+        endpoints = parser.to_endpoints()\n+        \n+        assert len(endpoints) == 2\n+        \n+        # Check Mutation\n+        mutation = next(e for e in endpoints if \"createUser\" in e[\"operation\"])\n+        assert mutation[\"path\"] == \"/api/graphql\"\n+        assert mutation[\"method\"] == \"POST\"\n+        assert mutation[\"fields\"][0][\"name\"] == \"username\"\n+        assert mutation[\"fields\"][0][\"type\"] == \"String!\"\n+        assert mutation[\"fields\"][0][\"required\"] is True\n+\n+        # Check Query\n+        query = next(e for e in endpoints if \"getUser\" in e[\"operation\"])\n+        assert query[\"fields\"][0][\"name\"] == \"id\"\n+        assert query[\"fields\"][0][\"type\"] == \"ID!\"\n+\n+    def test_resolve_type_name(self):\n+        \"\"\"Test type name resolution helper.\"\"\"\n+        parser = GraphQLParser()\n+        # Test List\n+        type_ref = {\"kind\": \"LIST\", \"ofType\": {\"kind\": \"SCALAR\", \"name\": \"String\"}}\n+        assert parser._resolve_type_name(type_ref) == \"[String]\"\n+\n+        # Test Non-Null\n+        type_ref = {\"kind\": \"NON_NULL\", \"ofType\": {\"kind\": \"SCALAR\", \"name\": \"Int\"}}\n+        assert parser._resolve_type_name(type_ref) == \"Int!\"\n+        \n+        # Test Simple\n+        type_ref = {\"kind\": \"SCALAR\", \"name\": \"Boolean\", \"ofType\": None}\n+        assert parser._resolve_type_name(type_ref) == \"Boolean\"\n+\n",
  "hints_text": "",
  "environment_setup_commit": "22425c5a0114f5557560008fc04c05aa15d77722",
  "install_config": {},
  "meta": {
    "commit_name": "head_commit",
    "num_modified_files": 4,
    "has_test_patch": true,
    "is_lite": false,
    "llm_score": {
      "difficulty_score": null,
      "issue_text_score": null,
      "test_score": null
    }
  },
  "license_name": "MIT",
  "FAIL_TO_PASS": [],
  "PASS_TO_PASS": [],
  "requirements": "",
  "environment": ""
}